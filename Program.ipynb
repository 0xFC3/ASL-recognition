{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "4.1.0\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import cv2\n",
    "import numpy\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##image taking function\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "def takeImage():\n",
    "    check, frame = cam.read()\n",
    "\n",
    "    #im_ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCR_CB)\n",
    "    #cv2.imwrite('hsu.png', im_ycrcb)\n",
    "    #skin_ycrcb_mint = numpy.array((0, 133, 77))\n",
    "    #skin_ycrcb_maxt = numpy.array((255, 173, 127))\n",
    "    #skin_ycrcb = cv2.inRange(im_ycrcb, skin_ycrcb_mint, skin_ycrcb_maxt)\n",
    "    #cv2.imwrite(sys.argv[2], skin_ycrcb) # Second image\n",
    "    #print(skin_ycrcb_maxt)\n",
    "    #contours, _ = cv2.findContours(skin_ycrcb, cv2.RETR_EXTERNAL,\n",
    "        #cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #for i, c in enumerate(contours):\n",
    "        #area = cv2.contourArea(c)\n",
    "        #if area > 1000:\n",
    "            #cv2.drawContours(frame, contours, i, (255, 0, 0), 3)\n",
    "    #cv2.imwrite('test.png', frame)\n",
    "    # Final image\n",
    "    cv2.imwrite(\"test.png\", frame)\n",
    "takeImage()\n",
    "#cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (fc1): Linear(in_features=25088, out_features=6000, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (drop): Dropout(p=0.5)\n",
      "    (fc2): Linear(in_features=6000, out_features=12, bias=True)\n",
      "    (output): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##NN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    \n",
    "    checkpoint = torch.load(filepath)\n",
    "    \n",
    "    if checkpoint['arch'] == 'vgg16':\n",
    "        \n",
    "        model = models.vgg16(pretrained=True)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Architecture not recognized.\")\n",
    "    \n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 6000)),\n",
    "                                            ('relu', nn.ReLU()),\n",
    "                                            ('drop', nn.Dropout(p=0.5)),\n",
    "                                            ('fc2', nn.Linear(6000, 12)),\n",
    "                                            ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "    model.classifier = classifier\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('NNs/ABCDEFGHIdns4Gextra1.pth')\n",
    "model.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('jsons/middle21.json', 'r') as f:\n",
    "    number_to_ASL = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def process_image(image_path):\n",
    "    # makes numpy image\n",
    "    \n",
    "\n",
    "    \n",
    "    pil_image = Image.open(image_path)\n",
    "    \n",
    "    # Resize\n",
    "    if pil_image.size[0] > pil_image.size[1]:\n",
    "        pil_image.thumbnail((5000, 256))\n",
    "    else:\n",
    "        pil_image.thumbnail((256, 5000))\n",
    "        \n",
    "    # Crop \n",
    "    left_margin = (pil_image.width-224)/2\n",
    "    bottom_margin = (pil_image.height-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "    \n",
    "    pil_image = pil_image.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
    "    \n",
    "    pil_image.save('cropped.png')\n",
    "    \n",
    "    # Normalize\n",
    "    np_image = np.array(pil_image)/255\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean) / std\n",
    "    \n",
    "\n",
    "    np_image = np_image.transpose((2, 0, 1))\n",
    "    \n",
    "    return np_image\n",
    "\n",
    "def predict(image_path, model, topk=3):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    image = process_image(image_path)\n",
    "    \n",
    "    # Convert image to PyTorch tensor first\n",
    "    image = torch.from_numpy(image).type(torch.cuda.FloatTensor)\n",
    "    #print(image.shape)\n",
    "    #print(type(image))\n",
    "    \n",
    "    # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    output = model.forward(image)\n",
    "    \n",
    "    probabilities = torch.exp(output)\n",
    "    \n",
    "    # Probabilities and the indices of those probabilities corresponding to the classes\n",
    "    top_probabilities, top_indices = probabilities.topk(topk)\n",
    "    \n",
    "    # Convert to lists\n",
    "    top_probabilities = top_probabilities.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    top_indices = top_indices.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    \n",
    "    # Convert topk_indices to the actual class labels using class_to_idx\n",
    "    # Invert the dictionary so you get a mapping from index to class.\n",
    "    \n",
    "    idx_to_class = {value: key for key, value in model.class_to_idx.items()}\n",
    "    #print(idx_to_class)\n",
    "    \n",
    "    top_classes = [idx_to_class[index] for index in top_indices]\n",
    "    \n",
    "    return top_probabilities, top_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to detect the actual sentence\n",
    "longer = False\n",
    "def detectSentence(hist, sentence):\n",
    "    global longer\n",
    "    last_el = hist[len(hist) - 1]\n",
    "    same = True\n",
    "    for element in hist:\n",
    "        if element != last_el:\n",
    "            same = False\n",
    "            longer = False\n",
    "    \n",
    "    if same == True and longer == False:\n",
    "        if last_el == \"nothing\":\n",
    "            pass\n",
    "        elif last_el == \"del\":\n",
    "            sentence = sentence[:-1]\n",
    "        elif last_el == \"space\":\n",
    "            sentence = sentence + ' '\n",
    "        else:\n",
    "            sentence = sentence + last_el\n",
    "        longer = True\n",
    "    \n",
    "    \n",
    "    return sentence\n",
    "\n",
    "\n",
    "##the pygame window \n",
    "pygame.init() \n",
    "pygame.font.init()\n",
    "\n",
    "myfont = pygame.font.SysFont('Comic Sans MS', 30)\n",
    "white = (255, 255, 255) \n",
    "\n",
    "X = 1000\n",
    "Y = 800\n",
    "\n",
    "display_surface = pygame.display.set_mode((X, Y ))\n",
    "run = True\n",
    "pygame.display.set_caption('ASL') \n",
    "\n",
    "hist = []\n",
    "sentence = ''\n",
    "while run == True : \n",
    "\n",
    "    display_surface.fill(white) \n",
    "    \n",
    "    probs, classes = predict('test.png', model) \n",
    "    #append last prediction to hist\n",
    "    hist.append(str(number_to_ASL[classes[0]]))\n",
    "    text = str(number_to_ASL[classes[0]]) + ': ' + str(probs[0]) + '    ' + str(number_to_ASL[classes[1]]) + ': ' + str(probs[1])\n",
    "    textsurface = myfont.render(text, False, (0, 0, 0))\n",
    "    display_surface.blit(textsurface,(50, 500))\n",
    "    #detect sentence\n",
    "    if len(hist)< 20: \n",
    "        sentence =detectSentence(hist, sentence)\n",
    "    else:\n",
    "        sentence = detectSentence(hist[len(hist)-20:], sentence)\n",
    "    sentsurface = myfont.render(sentence, False, (0, 0, 0))\n",
    "    display_surface.blit(sentsurface,(50, 580))\n",
    "    \n",
    "    image = pygame.image.load(r'test.png')\n",
    "    display_surface.blit(image, (0, 0)) \n",
    "    \n",
    "    cropped_image = pygame.image.load(r'cropped.png')\n",
    "    display_surface.blit(cropped_image, (700,0))\n",
    "    \n",
    "    pygame.display.update() \n",
    "    takeImage()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for event in pygame.event.get() : \n",
    "        if event.type == pygame.QUIT : \n",
    "  \n",
    "            pygame.quit() \n",
    "  \n",
    "            quit() \n",
    "            cam.release()\n",
    "            run = False\n",
    "     \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
