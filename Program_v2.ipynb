{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##image taking function\n",
    "import cv2\n",
    "\n",
    "def takeImage():\n",
    "    check, frame = cam.read()\n",
    "    cv2.imwrite(r\"test.png\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (fc1): Linear(in_features=25088, out_features=7000, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (drop): Dropout(p=0.5, inplace=False)\n",
      "    (fc2): Linear(in_features=7000, out_features=21, bias=True)\n",
      "    (output): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "##NN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os\n",
    "\n",
    "# Function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    \n",
    "    checkpoint = torch.load(filepath, map_location=torch.device('cpu')) ###ACHTUNG! auf CPU...\n",
    "    \n",
    "    if checkpoint['arch'] == 'vgg16':\n",
    "        \n",
    "        model = models.vgg16(pretrained=True)\n",
    "        \n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Architecture not recognized.\")\n",
    "    \n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 7000)),\n",
    "                                            ('relu', nn.ReLU()),\n",
    "                                            ('drop', nn.Dropout(p=0.5)),\n",
    "                                            ('fc2', nn.Linear(7000, 21)),\n",
    "                                            ('output', nn.LogSoftmax(dim=1))]))\n",
    "\n",
    "    model.classifier = classifier\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model\n",
    "## problems opening via relative path -> https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python\n",
    "script_dir = os.getcwd() #os.path.dirname(__file__) #<-- absolute dir the script is in (workingdir)\n",
    "rel_path = 'NNs\\\\ABCDEFGHIJKLMNOPQRdns4Gextra.pth'\n",
    "abs_file_path = os.path.join(script_dir, rel_path)\n",
    "\n",
    "model = load_checkpoint(abs_file_path)\n",
    "# model.cuda() ##STAY ON CPU\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'A', '2': 'B', '3': 'C', '4': 'D', '5': 'E', '6': 'F', '7': 'G', '8': 'H', '9': 'I', '10': 'J', '11': 'K', '12': 'L', '13': 'M', '14': 'N', '15': 'O', '16': 'P', '17': 'Q', '18': 'R', '19': 'S', '20': 'T', '21': 'U', '22': 'V', '23': 'W', '24': 'X', '25': 'Y', '26': 'Z', '27': 'del', '28': 'nothing', '29': 'space'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "## problems opening via relative path -> https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python\n",
    "script_dir = os.getcwd() #os.path.dirname(__file__) #<-- absolute dir the script is in (workingdir)\n",
    "rel_path = 'jsons\\\\big.json'\n",
    "abs_file_path = os.path.join(script_dir, rel_path)\n",
    "\n",
    "with open(abs_file_path, 'r') as f:\n",
    "    number_to_ASL = json.load(f)\n",
    "\n",
    "print(number_to_ASL)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def process_image(image_path):\n",
    "    # makes numpy image\n",
    "    \n",
    "    pil_image = Image.open(image_path)\n",
    "    \n",
    "    # Resize\n",
    "    if pil_image.size[0] > pil_image.size[1]:\n",
    "        pil_image.thumbnail((5000, 256))\n",
    "    else:\n",
    "        pil_image.thumbnail((256, 5000))\n",
    "        \n",
    "    # Crop \n",
    "    left_margin = (pil_image.width-224)/2\n",
    "    bottom_margin = (pil_image.height-224)/2\n",
    "    right_margin = left_margin + 224\n",
    "    top_margin = bottom_margin + 224\n",
    "    \n",
    "    pil_image = pil_image.crop((left_margin, bottom_margin, right_margin, top_margin))\n",
    "    \n",
    "    pil_image.save('cropped.png')\n",
    "    \n",
    "    # Normalize\n",
    "    np_image = np.array(pil_image)/255\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    np_image = (np_image - mean) / std\n",
    "    \n",
    "\n",
    "    np_image = np_image.transpose((2, 0, 1))\n",
    "    \n",
    "    return np_image\n",
    "\n",
    "def predict(image_path, model, topk=3):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    image = process_image(image_path)\n",
    "    \n",
    "    # Convert image to PyTorch tensor first\n",
    "    image = torch.from_numpy(image).type(torch.FloatTensor)\n",
    "    \n",
    "    # Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "    image = image.unsqueeze(0)\n",
    "    \n",
    "    output = model.forward(image)\n",
    "    \n",
    "    probabilities = torch.exp(output)\n",
    "    \n",
    "    # Probabilities and the indices of those probabilities corresponding to the classes\n",
    "    top_probabilities, top_indices = probabilities.topk(topk)\n",
    "    \n",
    "    # Convert to lists\n",
    "    top_probabilities = top_probabilities.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    top_indices = top_indices.detach().type(torch.FloatTensor).numpy().tolist()[0] \n",
    "    \n",
    "    # Convert topk_indices to the actual class labels using class_to_idx\n",
    "    # Invert the dictionary so you get a mapping from index to class.\n",
    "    \n",
    "    idx_to_class = {value: key for key, value in model.class_to_idx.items()}\n",
    "    #print(idx_to_class)\n",
    "    \n",
    "    top_classes = [idx_to_class[index] for index in top_indices]\n",
    "    \n",
    "    return top_probabilities, top_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-ideas:\n",
    "main loop analyzes *sequence* of predictions (over time) -> advantage of comparision, not the first best suggestion is recognized; goal is to 'flatten' _*somehow* (with functions)_ the noise, small fluctuations of the prediction propabilities;\n",
    "\n",
    "#### Different approaches: \n",
    "1. if sequence has all the time **one** leader, take it\n",
    "* look, if the last **two** (or top n) highest ranked classes*(if no big prop difference)* were amongst the sequence\n",
    "2. use means\n",
    "2. sum the probs of the sequence; take the \"highest\"   ⋅⋅⋅⋅⋅⋅⋅⋅⋅\n",
    "    *if difference is small, consider if you really make a decision or if you wait*\n",
    "2. arithmetic mean -> sum existence; weight in regard to rank position (1., 2., or 3. most likely prediction)⋅⋅⋅\n",
    "    *if difference is small, consider if you really make a decision or if you wait*\n",
    "    possibly improvable by considering propability differences (-> how telling the \"rank\" is)\n",
    "\n",
    "#### Discussion:\n",
    "1. very hardly compatible to slight variations / oscillations of the predictions due to little changes / insecureties\n",
    "2. little broader casting than 1., but also not immune to pred oscillations\n",
    "3. \n",
    "4. danger of honoring past events too much\n",
    "5. \" \n",
    "\n",
    "#### Conclusion:\n",
    "\n",
    "1. and \n",
    "2. : Combine with other methods ; making hist short makes the whole systems sensitive for noise\n",
    "3. \n",
    "4. and\n",
    "5. Use gradients / look for pro-changes, not stable variables, which were the top choice some time ago even though new signs are with high precision recognized by the system  => gradients   **OR**    make past events count less using prefactors etc.\n",
    "\n",
    "**For all:** \n",
    "Hardly any word has a 'Triple-B' or spells like 'NNNNNIIICCCEEEEE' => Uniform and cancel double chars out; *watch out, outstanding chars may disturb the spelling: 'BBBBAAABAAUUUUUMMMM' and can easily be detected...*\n",
    " \n",
    "For testing purposes it would be nice to create an visualisation of the probs for all chars.\n",
    "Or if multiple ways are realized, to have a way of comparision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def visualize_list(probs_list, name = 'dataplot.png'):\n",
    "    #Visualisation\n",
    "    global number_to_ASL\n",
    "    ABC = [value for key, value in number_to_ASL.items()]\n",
    "    ABC[-1] = \"' '\"\n",
    "    ABC[-2] = \"''\"\n",
    "    ABC[-3] = \"dl\"\n",
    "    plt.figure()\n",
    "    plt.bar(ABC, probs_list)\n",
    "    plt.ylabel('Summed propabilities over hist with prefactors')\n",
    "    plt.xlabel('Classes / Chars')\n",
    "    plt.title(name)\n",
    "    #Save to use it with pygame (is there an more intelligent solution?)\n",
    "    plt.savefig(name)\n",
    "    #plt.show\n",
    "    plt.close()\n",
    "\n",
    "def visualize_time_list(array, name = 'dataplot.png'):\n",
    "    global number_to_ASL\n",
    "    ABC = [value for key, value in number_to_ASL.items()]\n",
    "    ABC[-1] = \"' '\"\n",
    "    ABC[-2] = \"''\"\n",
    "    ABC[-3] = \"dl\"\n",
    "    ax = sns.heatmap(array, linewidth = 0.1)  # now using seaborn's heatmap\n",
    "    plt.xticks(np.arange(29), ABC)\n",
    "    plt.ylabel('Time of Prediction')\n",
    "    plt.xlabel('Classes / Chars')\n",
    "    plt.title(name)\n",
    "    plt.savefig(name)\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame  \n",
    "pygame.init()     ##the pygame window\n",
    "pygame.font.init()\n",
    "\n",
    "#critical for algorithm\n",
    "#Function to detect the actual sentence\n",
    "\n",
    "# Casting - Klasse !\n",
    "class DetectSentence:\n",
    "    myfont = pygame.font.SysFont('Comic Sans MS', 30) ##For changes: Copied to the DetectSentence - Class\n",
    "\n",
    "    def __init__(self, print_name, casting_function, sent_pos, dataplot_name = None, plot_pos = None):\n",
    "        self.sentence = print_name\n",
    "        self.readable_sentence = 'Casting N°'+print_name\n",
    "        self.casting_hist = []\n",
    "        self.dataplot_name = dataplot_name\n",
    "        self.sent_pos = sent_pos\n",
    "        self.plot_pos = plot_pos\n",
    "        self.print_name = print_name\n",
    "        self.last_char_nothing = False\n",
    "        #Set 'casting_function'\n",
    "        if casting_function == '2':\n",
    "            self.casting_function = self.casting2\n",
    "        elif casting_function == '4':\n",
    "            self.casting_function = self.casting4\n",
    "        elif casting_function == '5':\n",
    "            self.casting_function = self.casting5\n",
    "        elif casting_function == '6':\n",
    "            self.casting_function = self.casting6\n",
    "        elif casting_function == '7':\n",
    "            self.casting_function = self.casting7\n",
    "        else:\n",
    "            print(casting_function + \" failed\")\n",
    "\n",
    "        \n",
    "    def draw_on_pygame(self, screen):\n",
    "\n",
    "        sentsurface = self.myfont.render(self.readable_sentence, False, (0,0,0))\n",
    "        screen.blit(sentsurface, self.sent_pos)\n",
    "        \n",
    "        try: #maybe not useful (because old img is loaded)\n",
    "            plot_image = pygame.image.load(self.dataplot_name)\n",
    "            screen.blit(plot_image, self.plot_pos)\n",
    "        except:\n",
    "            pass #print(\"Error occured plot image: \" + self.print_name)\n",
    "\n",
    "    def refresh_sentence(self, hist):    \n",
    "        '''\n",
    "        Two steps:\n",
    "        1. search and find considerable / appropiate predictions for an char\n",
    "        2. if the function deciders there is an plausible prediction, it expands the handed over sentence\n",
    "        '''    \n",
    "        global number_to_ASL\n",
    "\n",
    "        best_choice_number = self.casting_function(hist)\n",
    "        best_char = number_to_ASL[best_choice_number]\n",
    "\n",
    "        if best_char == \"nothing\":\n",
    "            self.last_char_nothing = True\n",
    "            return\n",
    "        elif best_char == \"del\":\n",
    "            self.sentence = self.sentence[:-1]\n",
    "        elif best_char == \"space\":\n",
    "            self.sentence = self.sentence + ' '\n",
    "        else:\n",
    "            self.sentence = self.sentence + best_char\n",
    "        \n",
    "        #consistency_len =  1# could be any number, the longer the more strictly\n",
    "        if self.sentence[-3] == self.sentence[-2] == self.sentence[-1]:\n",
    "            if self.readable_sentence[-1] != self.sentence[-1]:\n",
    "                self.readable_sentence += self.sentence[-1]\n",
    "                self.last_char_nothing = False\n",
    "            elif self.last_char_nothing:\n",
    "                self.readable_sentence += self.sentence[-1]\n",
    "                self.last_char_nothing = False\n",
    "\n",
    "    \n",
    "    ## 2. : look, if the last **two / (topn)** highest ranked classes*(if no big prop difference)* were amongst the sequence\n",
    "    def casting2(self, hist):    \n",
    "        topn = 3 # must be smaller than topk\n",
    "        plausible_classes = list() #returns this list\n",
    "\n",
    "        last_pred = hist[-1]\n",
    "\n",
    "        for i in np.arange(topn):\n",
    "            topn_pred_i = last_pred[i][0]\n",
    "\n",
    "            plausible = True\n",
    "            for hist_pred in hist:\n",
    "                i_in_hist_pred = False\n",
    "                for hist_pred_class in hist_pred:\n",
    "                    if topn_pred_i == hist_pred_class[0]:\n",
    "                        i_in_hist_pred = True\n",
    "                if not i_in_hist_pred:\n",
    "                    plausible = False\n",
    "\n",
    "            if plausible:\n",
    "                plausible_classes.append(topn_pred_i)\n",
    "           \n",
    "        #norm result to one answer string\n",
    "        if plausible_classes:\n",
    "            return plausible_classes[0]\n",
    "        else:\n",
    "            return '28'\n",
    "\n",
    "    ## 4. sum the probs of the sequence; take the \"highest\"    *if difference is small, consider if you really make a decision or if you wait*\n",
    "    def casting4(self, hist, dataplot_name = 'casting4.png'):\n",
    "        probs_sums = np.zeros(29) # 30 or 29, but keep in mind:  change every i -> i-1\n",
    "\n",
    "        for time_stamp in np.arange(len(hist)):    #possible prefactor timeline\n",
    "            hist_pred = hist[time_stamp]\n",
    "            for rank in np.arange(len(hist_pred)): #possible prefactor prediction rank\n",
    "                hist_pred_class = hist_pred[rank]\n",
    "                class_number = int(hist_pred_class[0]) -1\n",
    "                prob = hist_pred_class[-1]\n",
    "                probs_sums[class_number] += prob * (time_stamp+1) #rank, timestamp could be 0\n",
    "        self.casting_hist.append(probs_sums)\n",
    "        visualize_time_list(self.casting_hist[-len(hist) : ], name = dataplot_name)\n",
    "\n",
    "        #norm result to one answer string\n",
    "        max_prob_class = np.argmax(probs_sums) +1 #returns the index of the maximum ; +1 to get the original class\n",
    "        return str(max_prob_class)\n",
    "\n",
    "\n",
    "    ## 5. arithmetic mean -> sum existence; weight in regard to rank position (1., 2., or 3. most likely prediction) *if difference is small, consider if you really make a decision or if you wait*    \n",
    "    def casting5(self, hist, dataplot_name = 'casting5.png'):\n",
    "        rank_list = np.zeros(29)\n",
    "        for time_stamp in np.arange(len(hist)):    #possible prefactor timeline\n",
    "            hist_pred = hist[time_stamp]\n",
    "            for rank in np.arange(len(hist_pred)): #possible prefactor prediction rank\n",
    "                hist_pred_class = hist_pred[rank]\n",
    "                class_number = int(hist_pred_class[0]) -1\n",
    "                rank_list[class_number] += 1/ (rank+1) #Consider: rank, timestamp could be 0 \n",
    "        self.casting_hist.append(rank_list)\n",
    "        visualize_time_list(self.casting_hist[-len(hist) : ], name = dataplot_name)\n",
    "\n",
    "        #norm result to one answer string\n",
    "        max_prob_class = np.argmax(rank_list) +1 #returns the index of the maximum ; +1 to get the original class\n",
    "        return str(max_prob_class)    \n",
    "\n",
    "\n",
    "    ## 6. arithmetic mean -> sum existence; weight in regard to rank position (1., 2., or 3. most likely prediction) *if difference is small, consider if you really make a decision or if you wait*    \n",
    "    def casting6(self, hist, dataplot_name = 'casting6.png'):\n",
    "        rank_list = np.zeros(29)\n",
    "        for time_stamp in np.arange(len(hist)):    #possible prefactor timeline\n",
    "            hist_pred = hist[time_stamp]\n",
    "            for rank in np.arange(len(hist_pred)): #possible prefactor prediction rank\n",
    "                hist_pred_class = hist_pred[rank]\n",
    "                class_number = int(hist_pred_class[0]) -1\n",
    "                rank_list[class_number] += 1/ (rank+1)**2 *(time_stamp+1) #Consider: rank, timestamp could be 0 \n",
    "        self.casting_hist.append(rank_list)\n",
    "        visualize_time_list(self.casting_hist[-len(hist) : ], name = dataplot_name)\n",
    "\n",
    "        #norm result to one answer string\n",
    "        max_prob_class = np.argmax(rank_list) + 1 #returns the index of the maximum ; +1 to get the original class\n",
    "        return str(max_prob_class)    \n",
    "\n",
    "    ## 7. arithmetic mean -> sum existence; weight in regard to rank position (1., 2., or 3. most likely prediction) *if difference is small, consider if you really make a decision or if you wait*    \n",
    "    def casting7(self, hist, dataplot_name = 'casting7.png'):\n",
    "        rank_list = np.zeros(29)\n",
    "        for time_stamp in np.arange(len(hist)):    #possible prefactor timeline\n",
    "            hist_pred = hist[time_stamp]\n",
    "            for rank in np.arange(len(hist_pred)): #possible prefactor prediction rank\n",
    "                hist_pred_class = hist_pred[rank]\n",
    "                class_number = int(hist_pred_class[0]) -1\n",
    "                prob = hist_pred_class[-1]\n",
    "                rank_list[class_number] += prob / ( (len(hist)-time_stamp) )#Consider: rank, timestamp could be 0 \n",
    "        self.casting_hist.append(rank_list)\n",
    "        visualize_time_list(self.casting_hist[-len(hist) : ], name = dataplot_name)\n",
    "\n",
    "        #norm result to one answer string\n",
    "        max_prob_class = np.argmax(rank_list) + 1 #returns the index of the maximum ; +1 to get the original class\n",
    "        return str(max_prob_class)    \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    global hist, propabilities_hist, Castings, display_surface, topk\n",
    "    topk = 3 #evtl global? oder \n",
    "    \n",
    "    ##the pygame window \n",
    "    pygame.init() \n",
    "    pygame.font.init()\n",
    "\n",
    "    X = 1500\n",
    "    Y = 800\n",
    "\n",
    "    display_surface = pygame.display.set_mode((X, Y))\n",
    "    \n",
    "    pygame.display.set_caption('ASL') \n",
    "    \n",
    "    hist = []\n",
    "    propabilities_hist = []\n",
    "    Castings = []\n",
    "    for i, casting in enumerate(['2', '4', '6', '7']):\n",
    "        name =['2: ', '4: ', '6: ', '7: '][i]\n",
    "        sent_pos = [(50, 600), (50, 630), (50, 660), (50, 690)][i]\n",
    "        plot_pos = [(0,0), (1100,270), (680,270), (1100,0)][i]\n",
    "        dataplot_name = [r'casting2', r'casting4.png', r'casting6.png', r'casting7.png'][i]\n",
    "        SearchInstance = DetectSentence(name, casting, sent_pos, plot_pos = plot_pos, dataplot_name = dataplot_name)\n",
    "        Castings.append(SearchInstance)\n",
    "        \n",
    "def main_loop_v2(hist_length):       \n",
    "    global hist, propabilities_hist, Castings, display_surface, topk\n",
    "    \n",
    "    myfont = pygame.font.SysFont('Comic Sans MS', 30) ##For changes: Copied to the DetectSentence - Class\n",
    "    white = (255, 255, 255) \n",
    "    black = (0, 0, 0)\n",
    "\n",
    "    for turn in np.arange(60):\n",
    "        \n",
    "        display_surface.fill(white) \n",
    "        \n",
    "        takeImage()\n",
    "        probs, classes = predict(r'test.png', model, topk = topk) \n",
    "        #append last prediction to hist ## Consider using np.array (and leaving the str (e.g. \"A\") out for data type conformity)        \n",
    "        hist.append( [ [classes[i] , number_to_ASL[classes[i]] , probs[i] ] for i in np.arange(topk)] )\n",
    "        \n",
    "        for i in np.arange(3):\n",
    "            pos = ((50, 500), (50, 530), (50, 560))[i]\n",
    "            text = str(number_to_ASL[classes[i]]) + ': ' + str(probs[i])\n",
    "            textsurface = myfont.render(text, False, black)\n",
    "            display_surface.blit(textsurface, pos)       \n",
    "        info  = 'Cycle N°: ' + str(turn) + ';  hist_length: ' + str(len(hist[-hist_length : ])) #+ '; topk: ' + str(topk)\n",
    "        infosurface  = myfont.render(info , False, (0,0,255))\n",
    "        display_surface.blit(infosurface, (700, 560))\n",
    "        \n",
    "        #if needed, crop hist to uniform length\n",
    "        #call DetectSentence\n",
    "        for casting in Castings:\n",
    "            if len(hist)< hist_length: \n",
    "                #casting.draw_on_pygame(display_surface, hist)\n",
    "                casting.refresh_sentence(hist)\n",
    "            else:\n",
    "                casting.refresh_sentence(hist[-hist_length : ])\n",
    "            casting.draw_on_pygame(display_surface)    \n",
    "        \n",
    "        propabilities = np.zeros(29)\n",
    "        for i in range(topk):\n",
    "            propabilities[int(classes[i])-1] = probs[i]\n",
    "        #visualize as 3D Plot of a timeline (Heatmap):\n",
    "        propabilities_hist.append(propabilities)\n",
    "        visualize_time_list(propabilities_hist[-hist_length : ], name = '3D-heatmap-probs over time.png')\n",
    "        probs_plot = pygame.image.load(r'3D-heatmap-probs over time.png')\n",
    "        display_surface.blit(probs_plot, (680, 0))\n",
    "        \n",
    "        image = pygame.image.load(r'test.png')\n",
    "        display_surface.blit(image, (0, 0)) \n",
    "\n",
    "        #cropped_image = pygame.image.load(r'cropped.png')\n",
    "        #display_surface.blit(cropped_image, (700,0))\n",
    "        \n",
    "        pygame.display.update() \n",
    "\n",
    "        for event in pygame.event.get() : \n",
    "            if event.type == pygame.QUIT or event.type == 'KEYDOWN' :\n",
    "                pygame.quit() \n",
    "\n",
    "                quit() \n",
    "                cam.release()\n",
    "                pass\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "if __name__ == \"__main__\":\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    takeImage()\n",
    "    \n",
    "    hist_length = 20 ### Maximum number of predictions which are taken into account in the computations\n",
    "    main_loop_v2(hist_length)\n",
    "    \n",
    "    cam.release()\n",
    "    #time.sleep(8)\n",
    "    #pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Teste Tastendruck -> Abbruchkriterium\n",
    "\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    time.sleep(1)\n",
    "    k = cv2.waitKey(0)\n",
    "    print(k)\n",
    "    if k == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7: AAAAAAAAAAAAAAAAABB\n"
     ]
    }
   ],
   "source": [
    "print(Castings[-1].sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
